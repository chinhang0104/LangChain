{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIg1TvIqECvs"
   },
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dB_-amzAEG-d",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8y-llLlq4Wgv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hsIroy9oB7vX"
   },
   "outputs": [],
   "source": [
    "# Store Access Token as an environment variable\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbDsOEH5D7JH",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvdnkaqOUupY"
   },
   "source": [
    " We first load sample document from the blog post contents by BeautifulSoup parser. Then, we will split the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0jO46y5CPzX",
    "outputId": "c31c8249-a32d-4ccc-b91b-30500a2d9a91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43130\n"
     ]
    }
   ],
   "source": [
    "# Load documents\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rp-GNF_D3IO",
    "outputId": "947c8f47-16fd-43d5-abbe-4b21729e450b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "# Splitting documents\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yJmj9bgESLc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setting up vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpUDojpfWQyA"
   },
   "source": [
    "We use Chroma as vectorstore and Groq as LLM. Since Groq does not provide embeddings, we will use HuggingFaceEmbeddings instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tUC3aAc0DGzG"
   },
   "outputs": [],
   "source": [
    "# Location of the database\n",
    "persist_directory = \"doc_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGldVUzcDM38",
    "outputId": "bf28847a-120e-423a-c774-cfa46592c167"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dfRGkPbYDUfP"
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkewmZBGE4H9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yZ8cWYgvDn7W"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZFA8HA1GEDXM"
   },
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Y7W9muFhSdv",
    "outputId": "fbb0dd10-ec2f-470e-db6b-aa0ff62b2f8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define prompt for question-answering\n",
    "# The template is: \"Answer any use questions based solely on the context below:\"\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm, retrieval_qa_chat_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sDUiW4a7Egkv"
   },
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YAxKyofXPdB",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Run query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "by3haRdRExV7"
   },
   "outputs": [],
   "source": [
    "query = \"What does the document say about LLM?\"\n",
    "response = retrieval_chain.invoke({\"input\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ynjGhG0IKDz",
    "outputId": "3ec0a564-42aa-4d72-968a-9531749a453e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What does the document say about LLM?',\n",
       " 'context': [Document(id='a329fd0a-b5f8-46d7-b526-7df16c47e95f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 20470}, page_content='API-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.'),\n",
       "  Document(id='ca89ce20-7767-4965-989b-c4f3dd189eea', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 20470}, page_content='API-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.'),\n",
       "  Document(id='7e8c6fc5-2480-4ba2-80f1-717992eb89a2', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39085}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'),\n",
       "  Document(id='1141cdac-e47b-4865-b5df-3a510655f73a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39085}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:')],\n",
       " 'answer': 'The document mentions that LLM (Large Language Model) has access to an API search engine to find the right API to call and then uses the corresponding documentation to make a call. This suggests that LLM is being used in conjunction with API tools to perform tasks.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKQGvWe8Xb5u"
   },
   "source": [
    "It runs successfully with relevent answers.  \n",
    "Check response['answer'] for response from the rag application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfOaAJvehjhj",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Set permission restriction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "armwEemIX5Ih"
   },
   "source": [
    "This part is an extra demo showing how to add access restriction to the rag application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "AY20XTYIhklx"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Add sample documents with permission control\n",
    "document1 = Document(\n",
    "    page_content=\"This is a report for finance department. The revenue of 2024 financial year is 100 million.\",\n",
    "    metadata={\"allowed_users\": \"user1\",\n",
    "              \"departments\": \"finance\"}\n",
    ")\n",
    "\n",
    "document2 = Document(\n",
    "    page_content=\"This is a report for HR department. The total employees at the end of 2024 is 10 thousands.\",\n",
    "    metadata={\"allowed_users\": \"user1\",\n",
    "              \"departments\": \"HR\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4O_kn81iQ4p",
    "outputId": "e00f3a73-f4c8-480f-8c3b-cc152fba67ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2bb2cd0d-9ace-4347-99ee-86a89b103c11',\n",
       " '4c464c98-affc-44d7-a0ad-136737f50060']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents([document1, document2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "w0ozrMqAq_SN"
   },
   "outputs": [],
   "source": [
    "# Permission of current user\n",
    "user_permissions = {\n",
    "    \"user_id\": [\"user1\"],\n",
    "    \"departments\": [\"finance\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "24wslsLtrH9l"
   },
   "outputs": [],
   "source": [
    "# Build filter for Chroma, loaded from current user permissions\n",
    "access_filter = {\n",
    "    \"$and\": [\n",
    "        {\"allowed_users\": {\"$in\": user_permissions[\"user_id\"]}},\n",
    "        {\"department\": {\"$in\": user_permissions[\"departments\"]}},\n",
    "    ]\n",
    "}\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 10,\n",
    "        \"filter\": access_filter  # Enforces access control\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a new retrieval chain with restriction to current user\n",
    "retrieval_chain_with_restriction = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "tQJRHZjxjXv7"
   },
   "outputs": [],
   "source": [
    "query = \"What is the revenue in 2024?\"\n",
    "response = retrieval_chain_with_restriction.invoke({\"input\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "7wARlUU1j-1s",
    "outputId": "3d7cb96f-d272-4321-bb9e-dccdafd2d468"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The revenue of 2024 financial year is 100 million.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "vyWMmM0MlPC4"
   },
   "outputs": [],
   "source": [
    "query = \"How many employees in 2024?\"\n",
    "response = retrieval_chain_with_restriction.invoke({\"input\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4aIfmPTAlVRK",
    "outputId": "6fe7174d-4c08-4d77-8fd5-86178e1cb421"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How many employees in 2024?',\n",
       " 'context': [],\n",
       " 'answer': \"I don't have any information about the number of employees in 2024. The provided context is empty.\"}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCLvrCQAynU9"
   },
   "source": [
    "The response showing the search is correctly limited due to departments restriction.  \n",
    "Let's compare with rag search without restriction below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "JX71cIIMyhws"
   },
   "outputs": [],
   "source": [
    "query = \"How many employees in 2024?\"\n",
    "response = retrieval_chain.invoke({\"input\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "cebcSCpQyk87",
    "outputId": "d36c0190-97f1-43a5-ef18-6e89324ff08f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'There are 10,000 employees at the end of 2024.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
